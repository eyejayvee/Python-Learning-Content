{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257bd0b-7f9e-4a51-aaf9-db95473a94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries that will be used in the project\n",
    "# Web scraping libraris\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Ablility to make HTTP requests\n",
    "import requests\n",
    "\n",
    "# Data visualization libraries\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Data processing libraries\n",
    "import pandas as pd\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7abd6",
   "metadata": {},
   "source": [
    "# **\"The cool thing about webscraping is that the internet becomes your database\"**\n",
    "- *Keith Galli*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11069395",
   "metadata": {},
   "source": [
    "## **What is Sentiment Analysis?**\n",
    "\n",
    "Sentiment analysis is analysing and quantifying the emotions within text and attributing a feeling towards them.  This is typically either positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608594b",
   "metadata": {},
   "source": [
    "## **Import libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6455172a",
   "metadata": {},
   "source": [
    "## **Get data**\n",
    "First thing we ned to do is choose a data source. I'll use [BBC News](https://www.bbc.co.uk/news) and choose an article URL.\n",
    "\n",
    "Pass that URL into the `website` as a `string` to declare, or instantiate, the `website` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9364fea-152f-4ac5-82f8-d8d6fb35fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the BBC newstory URL you would like to scrape\n",
    "website = 'https://www.bbc.co.uk/news/business-68230697'\n",
    "data = requests.get(website)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a6a925",
   "metadata": {},
   "source": [
    "Hopefully a response of 200 is returned after executing the next section of code, which means there is a successful connection to the target URL.\n",
    "\n",
    "Now let's take a look at the content:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cf984-41d2-49c5-941e-3b99669a56b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add .content onto the end of data\n",
    "data.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176af830",
   "metadata": {},
   "source": [
    "This data is really hard to work with, specific parts of the collected data need to be reviewed by investigating the website code, selecting each wrapper around each block of text, and then collecting the text.\n",
    "\n",
    "This is achieved by using `BeautifulSoup` to extract the data from the HTML code.\n",
    "\n",
    "Pass data.content into the `BeautifulSoup()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734832be-cf30-4d5f-8a8c-af4c16d5207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847ebca9",
   "metadata": {},
   "source": [
    "The webpage is converted into a `BeautifulSoup` object but it still doesn't look very user-friendly.\n",
    "\n",
    "The `find_all` function from `BeauitfulSoup` is used the collect everything which has this attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf8e161-249f-46a9-b7f0-bf5e68867cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_blocks = soup.find_all(\"div\", attrs={\"data-component\": \"text-block\"})\n",
    "text_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2a457",
   "metadata": {},
   "source": [
    "Use a `for loop` to isolate just the text from `text_blocks`.  \n",
    "\n",
    "What we need to do is make a `for` loop of text_blocks and then `print` the object `item.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e0721-0d22-478c-b667-af2d95d2e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop syntax:\n",
    "# for x in y:\n",
    "#       do something\n",
    "\n",
    "# Get just the text of each block using a loop:\n",
    "for item in text_blocks:\n",
    "  print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c87627",
   "metadata": {},
   "source": [
    "The webpage scraping is now complete. This is just plain text data.  Next steps:\n",
    "\n",
    "* Process it so we can visualise it with a word cloud.\n",
    "* Process it so the sentiment analyser can read it.\n",
    "\n",
    "Let's do our sentiment analysis first.\n",
    "\n",
    "# **Sentiment Analysis**\n",
    "\n",
    "**SPOILER ALERT**: News is often perceived as quite a \"negative\" source of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29801d87-3388-4947-83ab-3a2e33b4f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data for sentiment analyser:\n",
    "text_list = [item.text for item in text_blocks]\n",
    "\n",
    "# Pass in data to sentiment analyser:\n",
    "sentiment_analyser = pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "sentiments = sentiment_analyser(text_list)\n",
    "\n",
    "# Take a look at the sentiments:\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7340d21",
   "metadata": {},
   "source": [
    "The sentiment of every block is analysed. The next step is to process it again and place it into a `DataFrame` which is a kind of table that can be further analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eadfec4-0a2d-418d-bc36-5154bb2f9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment dictionary:\n",
    "sentiment_dictionary = {}\n",
    "i = 1\n",
    "for text, sentiment in zip(text_list, sentiments):\n",
    "  sentiment_dictionary[f\"block {i}\"] = {\n",
    "      \"text\": text,\n",
    "      \"sentiment_label\": sentiment[\"label\"],\n",
    "      \"sentiment_score\": sentiment[\"score\"]\n",
    "                                }\n",
    "  i += 1\n",
    "\n",
    "# Place the sentiment_dictionary into a DataFrame\n",
    "df = pd.DataFrame(data=sentiment_dictionary)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a7ad3",
   "metadata": {},
   "source": [
    "Transpose the results using pandas by calling our dataframe and adding .T onto the end of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2794df90-834e-49ad-9d26-ac297695ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3998fe3",
   "metadata": {},
   "source": [
    "Convert the sentiments into a new dataframe to which the sentiments can be measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6855a628-b46e-4905-b876-c66c5e8bf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create second dataframe with sentiment_labels and their counts\n",
    "df2 = pd.DataFrame(df[\"sentiment_label\"].value_counts())\n",
    "\n",
    "# Reset column names and rename\n",
    "df2 = df2.reset_index()\n",
    "df2.columns = ['sentiment', 'count']\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad18748",
   "metadata": {},
   "source": [
    "# **Data Visualisation**\n",
    "\n",
    "Creating a word cloud provides an idea of the wording used within the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f2ded-f6f8-47d9-ad7a-381c8a5473ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter these to change the size of the word cloud\n",
    "figsize_height = 20\n",
    "figsize_width = 10\n",
    "\n",
    "# Join all text into a single string:\n",
    "text_string = \" \".join([item.text for item in text_blocks])\n",
    "\n",
    "# Pass it into WordCloud:\n",
    "word_cloud = WordCloud(collocations = False, background_color = 'white', width=800, height=400).generate(text_string)\n",
    "\n",
    "# Create visualisation parameters:\n",
    "plt.figure(figsize=(figsize_height,figsize_width))\n",
    "plt.imshow(word_cloud,\n",
    "           interpolation='bilinear',\n",
    "           aspect=\"auto\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Visualise!\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5abe0b",
   "metadata": {},
   "source": [
    "Visualise the sentiments by percentage with a chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3a865-f355-4c81-a815-6254249eb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure colours\n",
    "positive = \"#777ae4\"\n",
    "negative =  \"#ee9247\"\n",
    "neutral = \"#e6e7f8\"\n",
    "\n",
    "# Compile pie chart\n",
    "chart = px.pie(df2,\n",
    "            hole =.5,\n",
    "            values='count',\n",
    "            names='sentiment',\n",
    "            color_discrete_map={\n",
    "                \"POS\": positive,\n",
    "                \"NEG\": negative,\n",
    "                \"NEU\": neutral\n",
    "            },\n",
    "            title='Pie chart showing percentage of sentiment')\n",
    "chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
